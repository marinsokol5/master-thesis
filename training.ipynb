{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m__init__.py\u001b[0m*  \u001b[34;42mdata\u001b[0m/             \u001b[01;32mtokenizator.ipynb\u001b[0m*  \u001b[01;32mtransformer.ipynb\u001b[0m*\r\n",
      "\u001b[34;42m__pycache__\u001b[0m/  \u001b[01;32mlightning.ipynb\u001b[0m*  \u001b[34;42mtokenizers\u001b[0m/\r\n",
      "\u001b[34;42mconstants\u001b[0m/    \u001b[34;42mmodels\u001b[0m/           \u001b[01;32mtraining.ipynb\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tokenizers\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(15, 10)})\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from constants import paths as p\n",
    "from constants import tokens as t\n",
    "from constants import hyperparameters as hp\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.callbacks as cb\n",
    "from models.lightning import IMDB_Reviews, TransformerLightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html  \n",
    "https://github.com/abrazinskas/FewSum/tree/master/fewsum/modelling/models  \n",
    "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html  \n",
    "https://colab.research.google.com/drive/1Uq5vIheRUuRbCplQe29aeSAi_fe-76v_#scrollTo=5Ed0vgI0PupK  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = IMDB_Reviews(p.TRAIN_TENSOR_DATASET_PATH, p.VALIDATION_TENSOR_DATASET_PATH, hp.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerLightning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 400])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[5.4169, 5.5481, 5.3064,  ..., 5.4332, 5.1129, 4.6798],\n",
       "        [5.0069, 5.1849, 4.1993,  ..., 5.0839, 5.9526, 4.8688],\n",
       "        [4.3287, 4.9560, 4.9175,  ..., 5.2828, 4.3712, 4.7301],\n",
       "        ...,\n",
       "        [5.6381, 5.9078, 4.1373,  ..., 4.6712, 4.7053, 5.0613],\n",
       "        [5.0040, 4.1237, 4.7372,  ..., 4.5835, 5.9708, 5.7477],\n",
       "        [4.5199, 6.0032, 5.2160,  ..., 4.3543, 5.4183, 5.2074]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(n, mean=5, std=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[5.4169, 5.5481, 5.3064,  ..., 5.4332, 5.1129, 4.6798],\n",
       "        [5.0069, 5.1849, 4.1993,  ..., 5.0839, 5.9526, 4.8688],\n",
       "        [4.3287, 4.9560, 4.9175,  ..., 5.2828, 4.3712, 4.7301],\n",
       "        ...,\n",
       "        [5.6381, 5.9078, 4.1373,  ..., 4.6712, 4.7053, 5.0613],\n",
       "        [5.0040, 4.1237, 4.7372,  ..., 4.5835, 5.9708, 5.7477],\n",
       "        [4.5199, 6.0032, 5.2160,  ..., 4.3543, 5.4183, 5.2074]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-7.9550e-01,  1.4021e-01,  1.6886e+00,  ..., -1.2174e+00,\n",
       "          6.3651e-01, -9.7681e-01],\n",
       "        [ 1.1089e+00,  1.2250e-01,  1.0834e-01,  ...,  8.7073e-01,\n",
       "          2.4968e-01, -7.4792e-03],\n",
       "        [ 1.6273e+00,  1.1973e-01, -5.5119e-01,  ..., -1.3389e+00,\n",
       "          1.9048e+00, -1.9424e+00],\n",
       "        ...,\n",
       "        [-1.7167e+00,  3.9627e-01,  2.4464e-01,  ..., -1.1313e+00,\n",
       "         -2.1135e-01,  3.9232e-01],\n",
       "        [-1.0144e+00,  2.8147e-01,  1.0556e+00,  ...,  1.0291e+00,\n",
       "          1.8795e-01,  1.5316e+00],\n",
       "        [ 1.0786e+00,  7.4860e-02, -7.7705e-01,  ..., -8.8402e-01,\n",
       "          1.8434e-03,  2.9670e-02]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_recommended_gain = nn.init.calculate_gain('relu')\n",
    "for parameter in model.parameters():\n",
    "    if parameter.dim() > 1:\n",
    "        nn.init.xavier_uniform_(parameter, gain=relu_recommended_gain)\n",
    "    else:\n",
    "        nn.init.normal_(parameter, std=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0221,  0.0080,  0.0132,  ...,  0.0049, -0.0175,  0.0228],\n",
       "        [-0.0040,  0.0204,  0.0008,  ..., -0.0239,  0.0174,  0.0168],\n",
       "        [ 0.0066,  0.0184,  0.0142,  ..., -0.0201, -0.0126, -0.0189],\n",
       "        ...,\n",
       "        [-0.0138,  0.0154,  0.0207,  ...,  0.0094,  0.0232,  0.0052],\n",
       "        [ 0.0221,  0.0213,  0.0176,  ...,  0.0008,  0.0178,  0.0074],\n",
       "        [ 0.0084,  0.0181, -0.0090,  ..., -0.0064,  0.0017, -0.0118]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20000, 400, padding_idx=3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerLightning(\n",
       "  (transformer): Transformer(\n",
       "    (embedder): Embedding(20000, 400, padding_idx=3)\n",
       "    (embedder_drouput): Dropout(p=0.1, inplace=False)\n",
       "    (embedding_layer): Sequential(\n",
       "      (0): Embedding(20000, 400, padding_idx=3)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (combine_embeddings_and_properties_layer): Linear(in_features=405, out_features=400, bias=True)\n",
       "    (positional_encoding_layer): PositionalEncoding(\n",
       "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=400, out_features=400, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "            (norm1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (transformer_to_vocabulary_logits_layer): Linear(in_features=400, out_features=20000, bias=True)\n",
       "  )\n",
       "  (loss_function): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "Cannot use GPUStatsMonitor callback because NVIDIA driver is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a058d5cd2507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPUStatsMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{epoch}_{validation_loss:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_top_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/gpu_stats_monitor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, memory_utilization, gpu_utilization, intra_step_time, inter_step_time, fan_speed, temperature)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             raise MisconfigurationException(\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;34m'Cannot use GPUStatsMonitor callback because NVIDIA driver is not installed.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             )\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: Cannot use GPUStatsMonitor callback because NVIDIA driver is not installed."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(progress_bar_refresh_rate=50, max_epochs=5, gpus=1, num_sanity_val_steps=1, callbacks=[cb.EarlyStopping(\"validation_loss\"), cb.GPUStatsMonitor(), cb.ModelCheckpoint(dirpath=\"./models\", filename='{epoch}_{validation_loss:.3f}', mode=\"min\", save_top_k=3, monitor=\"validation_loss\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
